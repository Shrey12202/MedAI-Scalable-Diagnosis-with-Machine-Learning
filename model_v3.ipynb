{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5548029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just to reset prometheus_client registry\n",
    "\n",
    "from prometheus_client import REGISTRY\n",
    "\n",
    "# Unregister all previously registered metrics\n",
    "for collector in list(REGISTRY._names_to_collectors.values()):\n",
    "    try:\n",
    "        REGISTRY.unregister(collector)\n",
    "    except KeyError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef4bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import json\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune import Tuner, TuneConfig\n",
    "from ray.train import Checkpoint, session\n",
    "\n",
    "from prometheus_client import start_http_server, Gauge, Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b563937",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"chexpert-jupyter\")  # name your experiment\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n",
    "\n",
    "train_loss_metric = Gauge(\"train_loss\", \"Training loss per epoch\", registry=None)\n",
    "val_loss_metric = Gauge(\"val_loss\", \"Validation loss\", registry=None)\n",
    "training_duration = Summary(\"training_duration_seconds\", \"Total training time\", registry=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a82f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minio credentials\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 14\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_CSV = \"sample_train.csv\"\n",
    "TEST_CSV = \"sample_test.csv\"\n",
    "IMG_ROOT = \".\"  # Current dir includes CheXpert-v1.0/\n",
    "\n",
    "LABELS = [\n",
    "    \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\", \"Lung Lesion\",\n",
    "    \"Edema\", \"Consolidation\", \"Pneumonia\", \"Atelectasis\", \"Pneumothorax\",\n",
    "    \"Pleural Effusion\", \"Pleural Other\", \"Fracture\", \"Support Devices\", \"No Finding\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ff4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Dataset\n",
    "# -----------------------\n",
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.df[LABELS] = self.df[LABELS].fillna(0).replace(-1, 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir, row[\"Path\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        labels = torch.tensor(row[LABELS].values.astype(\"float32\"))\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4eb650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Model\n",
    "# -----------------------\n",
    "class CheXpertModel(nn.Module):\n",
    "    def __init__(self, num_classes=14):\n",
    "        super().__init__()\n",
    "        base = models.densenet121(pretrained=True)\n",
    "        in_features = base.classifier.in_features\n",
    "        base.classifier = nn.Linear(in_features, num_classes)\n",
    "        self.model = base\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Transforms\n",
    "# -----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Load Data\n",
    "# -----------------------\n",
    "train_ds = CheXpertDataset(TRAIN_CSV, IMG_ROOT, transform)\n",
    "test_ds = CheXpertDataset(TEST_CSV, IMG_ROOT, transform)\n",
    "\n",
    "train_size = int(0.95 * len(train_ds))\n",
    "val_size = len(train_ds) - train_size\n",
    "train_subset, val_subset = random_split(train_ds, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Training Loop\n",
    "# -----------------------\n",
    "with training_duration.time():\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # 🔹 Start Prometheus server only ONCE (uncomment if needed)\n",
    "        # start_http_server(8004)\n",
    "\n",
    "        # 🔹 Log hyperparameters\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"epochs\", EPOCHS)\n",
    "        mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "\n",
    "        model = CheXpertModel(NUM_CLASSES).to(DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_model_path = \"best_model.pth\"\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            # ---- Training Phase ----\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for imgs, labels in train_loader:\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_loader)\n",
    "            print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f}\")\n",
    "            mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "            train_loss_metric.set(avg_train_loss)\n",
    "            scheduler.step(avg_train_loss)\n",
    "\n",
    "            # ---- Validation Phase ----\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for imgs, labels in val_loader:\n",
    "                    imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    preds = torch.sigmoid(outputs) >= 0.5\n",
    "                    correct += (preds == labels).sum().item()\n",
    "                    total += preds.numel()\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_accuracy = correct / total\n",
    "            print(f\"[Epoch {epoch+1}] Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "            mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "            val_loss_metric.set(avg_val_loss)\n",
    "\n",
    "            # Save best model\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"✅ Saved best model at epoch {epoch+1} (Val Loss: {avg_val_loss:.4f}, Acc: {val_accuracy:.4f})\")\n",
    "\n",
    "        # 🔹 Log final artifacts\n",
    "        mlflow.log_artifact(best_model_path)\n",
    "        mlflow.pytorch.log_model(model, \"final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Evaluation\n",
    "# -----------------------\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        outputs = torch.sigmoid(model(imgs)).cpu()\n",
    "        all_preds.append(outputs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "preds_binary = (all_preds >= 0.5).astype(int)\n",
    "\n",
    "# Compute accuracy (macro across all labels)\n",
    "correct = (preds_binary == all_labels).sum()\n",
    "total = preds_binary.size\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"\\n✅ Test Accuracy (avg over all labels): {accuracy:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# Display GT & Predictions as Disease Names\n",
    "# -----------------------\n",
    "def decode_labels(binary_labels):\n",
    "    return [LABELS[i] for i, val in enumerate(binary_labels) if val == 1]\n",
    "\n",
    "print(\"\\n📊 Ground Truth vs Predictions (first 6 images):\")\n",
    "for i in range(min(6, len(all_preds))):\n",
    "    gt_diseases = decode_labels(all_labels[i].astype(int))\n",
    "    pred_diseases = decode_labels(preds_binary[i])\n",
    "\n",
    "    print(f\"\\n🖼️ Image {i+1}:\")\n",
    "    print(\"🔹 Ground Truth Labels: \", gt_diseases if gt_diseases else [\"No Finding\"])\n",
    "    print(\"🔸 Predicted Labels:    \", pred_diseases if pred_diseases else [\"No Finding\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060aaa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
