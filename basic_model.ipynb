{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 14\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_CSV = \"data/train_cheXbert.csv\"\n",
    "VALID_CSV = \"data/valid.csv\"\n",
    "IMG_FOLDER = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# LABELS\n",
    "# -------------------------------\n",
    "CHEXPERT_LABELS = [\n",
    "    \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Enlarged Cardiomediastinum\",\n",
    "    \"Fracture\", \"Lung Lesion\", \"Lung Opacity\", \"No Finding\", \"Pleural Effusion\",\n",
    "    \"Pleural Other\", \"Pneumonia\", \"Pneumothorax\", \"Support Devices\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# DATASET\n",
    "# -------------------------------\n",
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_folder, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        # Replace NaNs and uncertain labels (-1) with 0\n",
    "        self.df[CHEXPERT_LABELS] = self.df[CHEXPERT_LABELS].fillna(0).replace(-1, 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_folder, row['Path'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        labels = torch.tensor(row[CHEXPERT_LABELS].values, dtype=torch.float32)\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2733c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# MODEL\n",
    "# -------------------------------\n",
    "class CheXpertModel(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CheXpertModel, self).__init__()\n",
    "        base = models.densenet121(pretrained=True)\n",
    "        in_features = base.classifier.in_features\n",
    "        base.classifier = nn.Linear(in_features, num_classes)\n",
    "        self.backbone = base\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# METRICS\n",
    "# -------------------------------\n",
    "def compute_auc(y_true, y_pred):\n",
    "    aucs = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "            aucs.append(auc)\n",
    "        except:\n",
    "            aucs.append(np.nan)\n",
    "    return np.nanmean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# TRAINING\n",
    "# -------------------------------\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels in tqdm(loader):\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            outputs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
    "            all_preds.append(outputs)\n",
    "            all_labels.append(labels.numpy())\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    return compute_auc(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebed1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                            [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load data\n",
    "train_ds = CheXpertDataset(TRAIN_CSV, IMG_FOLDER, transform=transform)\n",
    "valid_ds = CheXpertDataset(VALID_CSV, IMG_FOLDER, transform=transform)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# Model, optimizer, loss\n",
    "model = CheXpertModel().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_auc = validate(model, valid_loader)\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save(model.state_dict(), f\"checkpoint_epoch{epoch+1}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
